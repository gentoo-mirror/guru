BDEPEND=app-alternatives/ninja >=dev-build/cmake-3.20.5
DEFINED_PHASES=compile configure install prepare test
DEPEND=blas? ( virtual/blas ) cuda? ( dev-util/nvidia-cuda-toolkit:= ) hip? ( sci-libs/hipBLAS:= ) opencl? ( sci-libs/clblast:= ) sdl2? ( media-libs/libsdl2:= )
DESCRIPTION=Port of OpenAI's Whisper model in C/C++
EAPI=8
HOMEPAGE=https://github.com/ggml-org/whisper.cpp
INHERIT=cmake
IUSE=blas cuda hip opencl sdl2
KEYWORDS=~amd64
LICENSE=MIT
RDEPEND=blas? ( virtual/blas ) cuda? ( dev-util/nvidia-cuda-toolkit:= ) hip? ( sci-libs/hipBLAS:= ) opencl? ( sci-libs/clblast:= ) sdl2? ( media-libs/libsdl2:= )
REQUIRED_USE=?? ( blas cuda hip opencl )
SLOT=0
SRC_URI=https://github.com/ggml-org/whisper.cpp/archive/refs/tags/v1.7.6.tar.gz -> whisper.cpp-1.7.6.tar.gz
_eclasses_=toolchain-funcs	a6df79c1e9bc84369dbf3d44206ac772	flag-o-matic	a7afe42e95fb46ce9691605acfb24672	multiprocessing	1e32df7deee68372153dca65f4a7c21f	ninja-utils	2df4e452cea39a9ec8fb543ce059f8d6	xdg-utils	42869b3c8d86a70ef3cf75165a395e09	cmake	460729dc36f68cf03b044bc1d367e34a
_md5_=aa8f5a4a4a3f70c6a37194de89889bca
