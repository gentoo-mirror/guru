BDEPEND=app-alternatives/ninja >=dev-build/cmake-3.20.5 >=dev-lang/go-1.20:= app-arch/unzip virtual/pkgconfig
DEFINED_PHASES=compile configure install postinst preinst prepare pretend test unpack
DEPEND=cuda? ( dev-util/nvidia-cuda-toolkit:= ) blas? ( !mkl? ( virtual/blas ) mkl? ( sci-libs/mkl ) ) rocm? ( >=sci-libs/hipBLAS-5.5:=[amdgpu_targets_gfx908(-)?,amdgpu_targets_gfx90a(-)?,amdgpu_targets_gfx942(-)?,amdgpu_targets_gfx1030(-)?,amdgpu_targets_gfx1100(-)?,amdgpu_targets_gfx803(-)?,amdgpu_targets_gfx900(-)?,amdgpu_targets_gfx906(-)?,amdgpu_targets_gfx940(-)?,amdgpu_targets_gfx941(-)?,amdgpu_targets_gfx1010(-)?,amdgpu_targets_gfx1011(-)?,amdgpu_targets_gfx1012(-)?,amdgpu_targets_gfx1031(-)?,amdgpu_targets_gfx1101(-)?,amdgpu_targets_gfx1102(-)?,amdgpu_targets_gfx1200(-)?,amdgpu_targets_gfx1201(-)?] ) >=dev-lang/go-1.23.4
DESCRIPTION=Get up and running with Llama 3, Mistral, Gemma, and other language models.
EAPI=8
HOMEPAGE=https://ollama.com
INHERIT=cuda rocm cmake go-module systemd toolchain-funcs
IUSE=cpu_flags_x86_sse4_2 cpu_flags_x86_avx cpu_flags_x86_f16c cpu_flags_x86_avx2 cpu_flags_x86_bmi2 cpu_flags_x86_fma3 cpu_flags_x86_avx512f cpu_flags_x86_avx512vbmi cpu_flags_x86_avx512_vnni cpu_flags_x86_avx_vnni cuda blas mkl rocm +amdgpu_targets_gfx908 +amdgpu_targets_gfx90a +amdgpu_targets_gfx942 +amdgpu_targets_gfx1030 +amdgpu_targets_gfx1100 amdgpu_targets_gfx803 amdgpu_targets_gfx900 amdgpu_targets_gfx906 amdgpu_targets_gfx940 amdgpu_targets_gfx941 amdgpu_targets_gfx1010 amdgpu_targets_gfx1011 amdgpu_targets_gfx1012 amdgpu_targets_gfx1031 amdgpu_targets_gfx1101 amdgpu_targets_gfx1102 amdgpu_targets_gfx1200 amdgpu_targets_gfx1201
KEYWORDS=~amd64
LICENSE=MIT
RDEPEND=cuda? ( dev-util/nvidia-cuda-toolkit:= ) blas? ( !mkl? ( virtual/blas ) mkl? ( sci-libs/mkl ) ) rocm? ( >=sci-libs/hipBLAS-5.5:=[amdgpu_targets_gfx908(-)?,amdgpu_targets_gfx90a(-)?,amdgpu_targets_gfx942(-)?,amdgpu_targets_gfx1030(-)?,amdgpu_targets_gfx1100(-)?,amdgpu_targets_gfx803(-)?,amdgpu_targets_gfx900(-)?,amdgpu_targets_gfx906(-)?,amdgpu_targets_gfx940(-)?,amdgpu_targets_gfx941(-)?,amdgpu_targets_gfx1010(-)?,amdgpu_targets_gfx1011(-)?,amdgpu_targets_gfx1012(-)?,amdgpu_targets_gfx1031(-)?,amdgpu_targets_gfx1101(-)?,amdgpu_targets_gfx1102(-)?,amdgpu_targets_gfx1200(-)?,amdgpu_targets_gfx1201(-)?] ) acct-group/ollama >=acct-user/ollama-3[cuda?]
RESTRICT=test strip
SLOT=0
SRC_URI=https://github.com/ollama/ollama/archive/refs/tags/v0.9.0.tar.gz -> ollama-0.9.0.gh.tar.gz https://github.com/negril/gentoo-overlay-vendored/raw/refs/heads/blobs/ollama-0.9.0-vendor.tar.xz
_eclasses_=toolchain-funcs	f9d71a6efe9d083aec750dd13968e169	flag-o-matic	b892042b2667b8ac69ec8a2571dc290a	cuda	283d0f298f6c196c755a0f8d50daca85	rocm	ceb8f84b6d9c14021b983faab573ef93	multiprocessing	1e32df7deee68372153dca65f4a7c21f	ninja-utils	2df4e452cea39a9ec8fb543ce059f8d6	xdg-utils	42869b3c8d86a70ef3cf75165a395e09	cmake	02a4b2b45c23260fb969448904a8d9d9	go-env	0e2babf96e7d0b045fc07ad199eb2399	go-module	191a27261275fc3bff7dd7482361b5d6	systemd	a964c0cbe818b5729da1dbfcee5be861
_md5_=3f201dbb3b7be353e7b66500eb009a2b
