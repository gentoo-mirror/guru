BDEPEND=app-alternatives/ninja >=dev-build/cmake-3.20.5 >=dev-lang/go-1.20:= app-arch/unzip virtual/pkgconfig
DEFINED_PHASES=compile configure install postinst preinst prepare test unpack
DEPEND=cuda? ( dev-util/nvidia-cuda-toolkit:= ) blas? ( !mkl? ( virtual/blas ) mkl? ( sci-libs/mkl ) ) rocm? ( >=sci-libs/hipBLAS-5.5:=[amdgpu_targets_gfx906(-)?,amdgpu_targets_gfx908(-)?,amdgpu_targets_gfx90a(-)?,amdgpu_targets_gfx942(-)?,amdgpu_targets_gfx1030(-)?,amdgpu_targets_gfx1100(-)?,amdgpu_targets_gfx803(-)?,amdgpu_targets_gfx900(-)?,amdgpu_targets_gfx940(-)?,amdgpu_targets_gfx941(-)?,amdgpu_targets_gfx1010(-)?,amdgpu_targets_gfx1011(-)?,amdgpu_targets_gfx1012(-)?,amdgpu_targets_gfx1031(-)?,amdgpu_targets_gfx1101(-)?,amdgpu_targets_gfx1102(-)?] ) >=dev-lang/go-1.23.4
DESCRIPTION=Get up and running with Llama 3, Mistral, Gemma, and other language models.
EAPI=8
HOMEPAGE=https://ollama.com
INHERIT=cuda rocm cmake go-module systemd toolchain-funcs
IUSE=cpu_flags_x86_avx cpu_flags_x86_f16c cpu_flags_x86_avx2 cpu_flags_x86_fma3 cpu_flags_x86_avx512f cpu_flags_x86_avx512vbmi cpu_flags_x86_avx512_vnni cpu_flags_x86_avx512_bf16 cpu_flags_x86_avx_vnni cpu_flags_x86_amx_tile cpu_flags_x86_amx_int8 cuda blas mkl rocm +amdgpu_targets_gfx906 +amdgpu_targets_gfx908 +amdgpu_targets_gfx90a +amdgpu_targets_gfx942 +amdgpu_targets_gfx1030 +amdgpu_targets_gfx1100 amdgpu_targets_gfx803 amdgpu_targets_gfx900 amdgpu_targets_gfx940 amdgpu_targets_gfx941 amdgpu_targets_gfx1010 amdgpu_targets_gfx1011 amdgpu_targets_gfx1012 amdgpu_targets_gfx1031 amdgpu_targets_gfx1101 amdgpu_targets_gfx1102
KEYWORDS=~amd64
LICENSE=MIT
RDEPEND=cuda? ( dev-util/nvidia-cuda-toolkit:= ) blas? ( !mkl? ( virtual/blas ) mkl? ( sci-libs/mkl ) ) rocm? ( >=sci-libs/hipBLAS-5.5:=[amdgpu_targets_gfx906(-)?,amdgpu_targets_gfx908(-)?,amdgpu_targets_gfx90a(-)?,amdgpu_targets_gfx942(-)?,amdgpu_targets_gfx1030(-)?,amdgpu_targets_gfx1100(-)?,amdgpu_targets_gfx803(-)?,amdgpu_targets_gfx900(-)?,amdgpu_targets_gfx940(-)?,amdgpu_targets_gfx941(-)?,amdgpu_targets_gfx1010(-)?,amdgpu_targets_gfx1011(-)?,amdgpu_targets_gfx1012(-)?,amdgpu_targets_gfx1031(-)?,amdgpu_targets_gfx1101(-)?,amdgpu_targets_gfx1102(-)?] ) acct-group/ollama acct-user/ollama[cuda?]
RESTRICT=strip
SLOT=0
SRC_URI=https://github.com/ollama/ollama/archive/refs/tags/v0.6.4.tar.gz -> ollama-0.6.4.gh.tar.gz https://github.com/negril/gentoo-overlay-vendored/raw/refs/heads/blobs/ollama-0.6.4-vendor.tar.xz
_eclasses_=toolchain-funcs	f9d71a6efe9d083aec750dd13968e169	flag-o-matic	e8de74bac929ba17427e740e95707d00	cuda	283d0f298f6c196c755a0f8d50daca85	rocm	826765f795a41b937d1bfe8e709346cd	multiprocessing	1e32df7deee68372153dca65f4a7c21f	ninja-utils	2df4e452cea39a9ec8fb543ce059f8d6	xdg-utils	42869b3c8d86a70ef3cf75165a395e09	cmake	c0c9c21d01b8a96d2d736c554daedc57	go-env	0e2babf96e7d0b045fc07ad199eb2399	go-module	df32d29550d40a92da723d3b8e17b467	systemd	54bd206bb5c4efac6ae28b6b006713b0
_md5_=fd8f8cf27c72d6566711ae5943927951
